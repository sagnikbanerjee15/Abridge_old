#! /usr/bin/env python3

########################################################################################################################################################
# The software 'abridge' will compress aligned files to a bare minimum needed for generating assemblies and producing read counts
#
# Changelist

# Only a single type of compression zpaq
# Altering of read names
########################################################################################################################################################

from argparse import RawTextHelpFormatter
import argparse
import logging
import os
import pprint
import sys
import re
import time
import multiprocessing
import random
import glob
import time
import subprocess
from pprint import pformat

from scripts.assessMemoryRequirement import *
from scripts.verifyPositions import *
from scripts.sortPositionsForRandomAccess import *


def parseCommandLineArguments():
    parser = argparse.ArgumentParser( prog = "run_abridge", description = "Compress alignments for storage, decompress from compressed file, view alignments from random locations and generate coverages", formatter_class = RawTextHelpFormatter )
    required_named = parser.add_argument_group( 'Required arguments' )
    optional_named = parser.add_argument_group( 'Optional arguments' )

    # Required arguments
    required_named.add_argument( "-o", "--output_directory", help = "Enter the name of the output directory. If nothing is specified then the compressed file will be put in the same location as the input samfile" )
    required_named.add_argument( "-g", "--genome", help = "Enter a single fasta file for the reference", required = True )

    input_group = parser.add_mutually_exclusive_group( required = True )
    input_group.add_argument( "-isam", "--inputfilename", help = "Enter the name of the alignment file you wish to compress. Alignments in SAM format only is expected. Ensure that the file is sorted by coordinate. Also, files must have the header section with the reference information available. You can compress only one file at a time." )
    input_group.add_argument( "-iabr", "--inputabrfilename", help = "Enter the name of the compressed alignment files you wish to merge. These files must be compressed using abridge. You can decompress only one file at a time." )

    compress_decompress_group = parser.add_mutually_exclusive_group( required = True )
    compress_decompress_group.add_argument( "-cmp", "--compress", help = "Set this option if you wish to compress the alignment file", action = "store_true" )
    compress_decompress_group.add_argument( "-dcmp", "--decompress", help = "Set this option if you wish to decompress the alignment file", action = "store_true" )
    # compress_decompress_group.add_argument( "-r", "--random", help = "Retrieve alignments from random locations", action = "store_true" )
    compress_decompress_group.add_argument( "-H", "--header", help = "Print only the header of reference sequences during decompression", action = "store_true" )

    # Optional arguments
    # optional_named.add_argument( "-l", "--level", help = "This can accept an integer from the set (1,2,3). If level is set to 1 then abridge will perform the fastest but low compression. abridge will use brotli to compress. Decompression will be fast. Setting level to 2 will prompt abridge to perform the medium level compression using 7z. Compression will take time but decompression will be fast. If level is set to 3 then abridge will perform the best compression using 7paq. Both compression and decompression will take average time to complete", type = int, default = 2 )
    optional_named.add_argument( "-skip_shortening_read_names", "--skip_shortening_read_names", help = "Request abridge to skip the step to reduce the size of read names. This options takes a bit longer but leads to much higher compression without adding to decompression time", action = "store_true" )
    optional_named.add_argument( "-ss", "--ignore_alignment_scores", help = "Request abrigde to store the quality scores and the alignment score", action = "store_true" )
    optional_named.add_argument( "-igqual", "--ignore_quality_scores_for_mismatched_bases_and_soft_clips", help = "Ignore all quality scores", action = "store_true" )
    optional_named.add_argument( "-qual", "--quality", help = "Enter dummy quality scores while decompressing", default = 'I' )
    optional_named.add_argument( "-gsc", "--ignore_soft_clippings", help = "No soft clippings will be stored. Read will be trimmed down to only the portion which matched to nucleotides in the reference", action = "store_true" )
    optional_named.add_argument( "-gm", "--ignore_mismatches", help = "All mismatches will be ignored", action = "store_true" )
    optional_named.add_argument( "-gs", "--ignore_sequence", help = "No nucleotide sequence will be produced during decompression", action = "store_true" )
    optional_named.add_argument( "-gu", "--ignore_unmapped_reads", help = "Request abridge to discard all reads that are unmapped", action = "store_true" )
    optional_named.add_argument( "-sq", "--ignore_quality_scores_for_matched_bases", help = "Request abridge to save all quality scores", action = 'store_true' )
    # optional_named.add_argument( "-aq", "--save_exact_quality_scores", help = "Adjust quality scores for matched bases to achieve better encoding. For more details please check ...", action = "store_true" )
    optional_named.add_argument( "-q", "--quiet", help = "Prevent abridge from printing any log information. By default logging is enables", action = "store_true" )
    optional_named.add_argument( "-n", "--cpu", help = "Enter the number of CPU cores to be used. This option will be used during compression or decompression.", default = 1 )
    optional_named.add_argument( "-run_diagnostics", "--run_diagnostics", help = "abridge will run diagnostics on the cigar compression and decompression. It will exit on discovery of any discrepancies", action = "store_true" )
    optional_named.add_argument( "-p", "--positions", help = "Enter the position as chromosome:start-end from which reads will be retrieved" )
    optional_named.add_argument( "-rp", "--read_prefix", help = "Enter a read prefix for decompression - valid only for random access" )
    optional_named.add_argument( "--keep_intermediate_error_files", "-keep_intermediate_error_files", help = "Set this argument if you wish to preserve the intermediate error files to assess time and memory usage. Default behaviour is to delete those", action = "store_true" )
    optional_named.add_argument( "--error_directory", "-edir", help = "Enter a directory where all error files will be stored. If nothing is specified then error files will be stored in the output directory" )
    optional_named.add_argument( "--framework", "-fm", help = "Enter your choice of framework", choices = ["docker", "singularity"], default = "docker" )
    optional_named.add_argument( "--force", "-force", help = "Setting this argument will remove the output directory and start the computation from scratch", action = "store_true" )
    optional_named.add_argument( "--skip_modifying_read_names", "-skip_modifying_read_names", help = "Avoid renaming the reads to save space. Please note that enabling this option will lead to larger file sizes", action = "store_true" )
    optional_named.add_argument( "--preserve_all_intermediate_files", "-preserve_all_intermediate_files", help = "Set this option to preserve all the intermediate files", action = "store_true" )

    # Suppressed arguments
    parser.add_argument( "--logfilename", "-logfilename", help = argparse.SUPPRESS )  # Name of the logfile
    parser.add_argument( "--files_for_removal", "-files_for_removal", help = argparse.SUPPRESS )  # Files will be removed later
    parser.add_argument( "--softwares", "-softwares", help = argparse.SUPPRESS )  # Software paths
    parser.add_argument( "--single_ended", "-single_ended", help = argparse.SUPPRESS )
    parser.add_argument( "--reference_to_length", "-num_of_reference_sequences", help = argparse.SUPPRESS )
    parser.add_argument( "--outputfilename", "-outputfilename", help = argparse.SUPPRESS )
    parser.add_argument( "--compile_programs", "-compile_programs", action = "store_true", help = argparse.SUPPRESS )  # Force abridge to compile the C programs

    # Future enhancements
    compress_decompress_group.add_argument( "-ov", "--generate_overlapping_coverage", help = argparse.SUPPRESS, action = "store_true" )  # Future - This option can be used in conjuction with --positions to construct coverage from a specific location # help="Enter the name of the compressed file from which you wish to generate an overlapping coverage of reads ",
    compress_decompress_group.add_argument( "-nov", "--generate_non_overlapping_coverage", help = argparse.SUPPRESS, action = "store_true" )  # help="Enter the name of the compressed file from which you wish to generate a non-overlapping coverage of reads "

    # Options for generating coverage
    optional_named.add_argument( "-d", "--d", help = argparse.SUPPRESS, action = "store_true" )  # help = "Report the depth at each position in each A feature. Positions reported are one based.  Each position and depth follow the complete A feature.",
    optional_named.add_argument( "-bg", "--bg", help = argparse.SUPPRESS, action = "store_true" )
    optional_named.add_argument( "-bga", "--bga", help = argparse.SUPPRESS, action = "store_true" )
    optional_named.add_argument( "-split", "--split", help = argparse.SUPPRESS, action = "store_true" )  # help = "Treat \"split\" BAM or BED12 entries as distinct BED intervals.",
    optional_named.add_argument( "-mem", "--max_memory", help = argparse.SUPPRESS, default = 10 )  # help="Enter the maximum memory allowed (in GB)"
    optional_named.add_argument( "-t", "--produce_tags", help = argparse.SUPPRESS, nargs = "*" )  # help="Enter a comma separated list of tags that you want abridge to produce during decompression. By default abridge will generate NH, MD and XS tags."
    return parser.parse_args()


def configureLogger( options ):
    if os.path.exists( options.logfilename ) == True:
        os.system( f"rm -f {options.logfilename}" )
    logging.basicConfig( format = '%(asctime)s - %(message)s', datefmt = '%d-%b-%y %H:%M:%S', level = logging.DEBUG, filename = options.logfilename )


def runDockerCommand( logging, name, version, image_location, container_name, volumes, command , cpus = 1, memory = '1g' ):
    """
    Runs the command in a docker container
    """

    # Runs the main command
    docker_cmd = f" docker run "
    # docker_cmd += f" -ti "
    docker_cmd += f" --rm "
    docker_cmd += f" --cpus={cpus}"
    docker_cmd += f" --memory='{memory}'"
    # docker_cmd += f" --name {container_name}"
    for mapping in volumes:
        docker_cmd += f" -v {mapping}"
    docker_cmd += f" {image_location}:{version} "
    docker_cmd += f" bash -c '{command}'"
    os.system( docker_cmd )
    logging.info( f"Running command - {docker_cmd}" )


def runSingularityCommand( logging, name, version, image_location, container_name, volumes, command , cpus = 1, memory = '1g' ):
    """
    Runs the command in a Singularity container
    """

    # Runs the main command
    singularity_cmd = f" singularity exec  "
    # singularity_cmd += f" --hostname {container_name}"
    for mapping in volumes:
        singularity_cmd += f" -B {mapping}"
    singularity_cmd += f" abridge_{version}.sif "
    singularity_cmd += f" bash -c {command}"
    os.system( singularity_cmd )
    # print( singularity_cmd )
    logging.info( f"Running command - {singularity_cmd}" )


def validateCommandLineArguments( options ):
    """
    """
    if options.compress == True and options.inputfilename is None and options.inputabrfilename is not None:
        print( "For compression you need to provide a list of space spearated samfiles using -isam " )
        if options.quiet == False:
            logging.info( "For compression you need to provide a list of space spearated samfiles using -isam " )
        sys.exit()
    if options.decompress == True and options.inputfilename is not None and options.inputabrfilename is None:
        print( "For decompression you need to provide a list of abridge compressed files using -iabr" )
        if options.quiet == False:
            logging.info( "For decompression you need to provide a list of abridge compressed files using -iabr" )
        sys.exit()
    if options.inputfilename is not None:
        inputfiles = options.inputfilename
    else:
        inputfiles = options.inputabrfilename

    if os.path.exists( inputfiles ) == False:
        print( f"The input file {inputfiles} does not exist. Exiting..." )
        if options.quiet == False:
            logging.info( f"The input file {inputfiles} does not exist. Exiting..." )
        sys.exit()

    # Check if the input format is sam
    if options.inputfilename is not None:
        if ( options.inputfilename[-3:] != "sam" and options.inputfilename[-3:] != "bam" ) and options.compress == True:
            print( f"The input file {options.inputfilename} needs to be in either sam or bam format. Exiting..." )
            if options.quiet == False:
                logging.info( f"The input file {options.inputfilename} needs to be in sam format. Exiting..." )
            sys.exit()

    options.files_for_removal = []
    options.softwares = {}

    if options.generate_overlapping_coverage == True or options.generate_non_overlapping_coverage == True:
        options.output_directory = "/".join( options.inputabrfilename.split( "/" )[:-1] ) + "/" + str( int( time.time() ) )
        os.system( f"mkdir -p {options.output_directory}" )

    """
    if options.random == True and options.positions == None:
        print( "You need to enter at least one location from where reads will be retrieved" )
        sys.exit()

    if options.random == True and options.inputabrfilename is None:
        print( f"You need to provide one compressed file for random access" )
        sys.exit()

    if options.random == True and options.inputfilename is not None:
        print( f"You need to provide one compressed file for random access" )
        sys.exit()
    """
    if options.error_directory == None:
        options.error_directory = options.output_directory
    else:
        os.system( f"mkdir -p {options.error_directory}" )

    # ignore_quality_scores_for_matched_bases has higher priority
    if options.ignore_quality_scores_for_matched_bases == False and options.ignore_quality_scores_for_mismatched_bases_and_soft_clips == False:
        options.ignore_quality_scores_for_mismatched_bases_and_soft_clips = True

    options.softwares["determineEndedness"] = "determineEndedness"
    options.softwares["compressSamFileSingleEnded"] = "compressSamFileSingleEnded"
    options.softwares["compressSamFileSingleEndedPass2"] = "compressSamFileSingleEndedPass2"
    options.softwares["compressSamFilePairedEnded"] = "compressSamFilePairedEnded"
    options.softwares["splitSamFileIntoEachReferenceSequence"] = "splitSamFileIntoEachReferenceSequence"
    options.softwares["buildABRIDGEIndex"] = "buildAbridgeIndex"
    options.softwares["decompressSamFileSingleEnded"] = "decompressSamFileSingleEnded"
    options.softwares["extractSequencesFromReferences"] = "extractSequencesFromReferences.py"
    options.softwares["randomRetrievalSingleEnded"] = "randomRetrievalSingleEnded"
    options.softwares["randomRetrievalPairedEnded"] = "randomRetrievalPairedEnded"
    options.softwares["mergeCompressedFilesSingleEnded"] = "mergeCompressedFilesSingleEnded"
    options.softwares["addTagToSamFile"] = "addTagToSamFile"
    options.softwares["maxReadsMappedToSingleNucleotide"] = "maxReadsMappedToSingleNucleotide"
    options.softwares["compressQualityScoresFile"] = "compressQualityScoresFile"
    options.softwares["deCompressQualityScoresFile"] = "deCompressQualityScoresFile"
    options.softwares["compressSamFilePairedEnded"] = "compressSamFilePairedEnded"
    options.softwares["decompressSamFilePairedEnded"] = "decompressSamFilePairedEnded"
    options.softwares["generateCoverage"] = "generateCoverage"
    options.softwares["findMaximumNumberOfReadsInEachLine"] = "findMaximumNumberOfReadsInEachLine"
    options.softwares["maxReadsInEachLine"] = "maxReadsInEachLine"
    options.softwares["associateShortNamesToReads"] = "associateShortNamesToReads"

    if options.decompress == True:
        if options.inputabrfilename[-8:] != ".abridge":
            print( f"The input file {options.inputabrfilename} needs to be in abridge format. Exiting..." )
            if options.quiet == False:
                logging.info( f"The input file {options.inputabrfilename} needs to be in abridge format. Exiting..." )
            sys.exit()

    if options.ignore_soft_clippings == True:
        options.ignore_soft_clippings = 1
    else:
        options.ignore_soft_clippings = 0

    if options.ignore_mismatches == True:
        options.ignore_mismatches = 1
    else:
        options.ignore_mismatches = 0

    if options.ignore_sequence == True:
        options.ignore_sequence = 1
    else:
        options.ignore_sequence = 0

    if options.ignore_unmapped_reads == True:
        options.ignore_unmapped_reads = 1
    else:
        options.ignore_unmapped_reads = 0

    if options.generate_overlapping_coverage == False and options.generate_non_overlapping_coverage == False:
        if True in [options.d, options.bg, options.bga, options.split]:
            print( "Incorrect arguments. Please provide arguments -d -bg -bga or -split only when you wish to generate coverage" )
            if options.quiet == False:
                logging.info( "Incorrect arguments. Please provide arguments -d -bg -bga or -split only when you wish to generate coverage" )
            sys.exit()

    if options.generate_overlapping_coverage == True and options.generate_non_overlapping_coverage == True:
        print( "You can either generate overlapping or non-overlapping coverage. If you need to generate both please run abridge twice each time with either option" )
        if options.quiet == False:
            logging.info( "You can either generate overlapping or non-overlapping coverage. If you need to generate both please run abridge twice each time with either option" )
        sys.exit()

    if options.generate_overlapping_coverage == False or options.generate_non_overlapping_coverage == False:
        if [options.d, options.bg, options.bga].count( True ) > 1:
            print( "You can specify only one among -d, -bg or -bga" )
            if options.quiet == False:
                logging.info( "You can specify only one among -d, -bg or -bga" )
            sys.exit()

    if options.inputfilename is not None:
        input_filename_without_location = options.inputfilename.split( "/" )[-1][:-4]
    else:
        input_filename_without_location = options.inputabrfilename.split( "/" )[-1][:-8]
    options.outputfilename = f"{options.output_directory}/{input_filename_without_location}.abridge"


def checkSAMAlignments( options, logging ):
    """
    """

    if "SO:coordinate" not in open( f"{options.inputfilename}", "r" ).readline():
        print( f"The file {options.inputfilename} is not sorted. Exiting" )
        if options.quiet == False:
            logging.info( f"The file {file} is not sorted. Exiting" )
        sys.exit()

    # Verify that all the headers are exactly same
    headers = []

    fhr = open( f"{options.inputfilename}", "r" )
    header = ""
    for line in fhr:
        if line[:3] == '@SQ' or line[:3] == "@HD":
            header += line
        else:
            if "NH:i" in line or "XM:i" in line:
                NH_present = 1
            else:
                NH_present = 0
            break
    headers.append( header )
    if len( set( headers ) ) != 1:
        print( "All the headers must be same. Please check your bamfile. Exiting..." )
        if options.quiet == False:
            logging.info( "All the headers must be same. Please check your bamfile. Exiting..." )
            sys.exit()
    return NH_present


def cleanUp( options ):
    # Remove the genome files
    genome_filename_without_location = options.genome.split( "/" )[-1]
    options.genome = f"{options.output_directory}/{genome_filename_without_location}"
    os.system( f"rm -rf {options.genome}*" )

    return
    for file in options.files_for_removal:
        cmd = f"rm -rf {file}"
        os.system( cmd )


def runCommand( eachpinput ):
    cmd, dummy = eachpinput
    os.system( cmd )


def constructFileNames( input_filename, options ):
    name_of_input_file_without_location = input_filename.split( "/" )[-1][:-4]

    name_of_max_input_reads_file = f"{options.output_directory}/{name_of_input_file_without_location}_max_input_reads"
    name_of_file_with_max_commas = f"{options.output_directory}/{name_of_input_file_without_location}_max_commas"
    name_of_file_max_read_length = f"{options.output_directory}/{name_of_input_file_without_location}_max_read_size"
    name_of_total_number_of_alignments_file = f"{options.output_directory}/{name_of_input_file_without_location}_total_number_of_alignments"
    frequency_of_flags_filename = f"{options.output_directory}/{name_of_input_file_without_location}_frequency_of_flags"

    outputfilename = f"{options.output_directory}/{name_of_input_file_without_location}_compressed"
    index_outputfilename = f"{options.output_directory}/{name_of_input_file_without_location}_index"
    unmapped_outputfilename = f"{options.output_directory}/{name_of_input_file_without_location}_unmapped"
    name_of_file_with_quality_scores = f"{options.output_directory}/{name_of_input_file_without_location}_qual"
    name_of_file_with_quality_scores_rle = f"{options.output_directory}/{name_of_input_file_without_location}_qual_rle"
    name_of_file_dictionary = f"{options.output_directory}/{name_of_input_file_without_location}.dictionary"
    fclqc_output_filename = f"{options.output_directory}/{name_of_input_file_without_location}_qual_compressed_fclqc"

    error_file_max_input_reads = f"{name_of_max_input_reads_file}.error"
    error_file_compress_ = f"{outputfilename}.error"
    error_file_prep_abridge_index = f"{index_outputfilename}.error"
    error_file_qual_rle = f"{name_of_file_with_quality_scores_rle}.error"
    error_fclqc = f"{fclqc_output_filename}.error"

    error_file_7z_compression = f"{options.error_directory}/{name_of_input_file_without_location}_7z_compression.error"
    error_file_zpaq_compression = f"{options.error_directory}/{name_of_input_file_without_location}_zpaq_compression.error"
    error_file_brotli_compression = f"{options.error_directory}/{name_of_input_file_without_location}_brotli_compression.error"

    # Decompression
    error_file_7z_decompression = f"{options.error_directory}/{name_of_input_file_without_location}_7z_decompression.error"
    error_file_zpaq_decompression = f"{options.error_directory}/{name_of_input_file_without_location}_zpaq_decompression.error"
    error_file_brotli_decompression = f"{options.error_directory}/{name_of_input_file_without_location}_brotli_decompression.error"

    delete_these_files = [name_of_max_input_reads_file, name_of_file_with_max_commas, name_of_file_max_read_length, name_of_total_number_of_alignments_file, frequency_of_flags_filename]
    other_files = [outputfilename, index_outputfilename, unmapped_outputfilename, name_of_file_with_quality_scores, name_of_file_with_quality_scores_rle, name_of_file_dictionary, fclqc_output_filename]
    error_files = [error_file_max_input_reads, error_file_compress_, error_file_qual_rle, error_file_prep_abridge_index, error_file_7z_compression, error_file_zpaq_compression, error_file_brotli_compression, error_file_7z_decompression, error_file_zpaq_decompression, error_file_brotli_decompression, error_fclqc]
    # compressed_files = [compressed_abridged_filename_br,compressed_abridged_filename_zpaq]
    return  delete_these_files, other_files, error_files


def compressSamFile( options , list_of_softwares_with_versions, volumes_list ):
    """
    """
    pool = multiprocessing.Pool( processes = int( options.cpu ) )
    files_to_be_removed = []
    input_filename = options.inputfilename
    name_of_input_file_without_location = input_filename.split( "/" )[-1]
    delete_these_files, other_files, error_files = constructFileNames( input_filename, options )
    name_of_max_input_reads_file, name_of_file_with_max_commas, name_of_file_max_read_length, name_of_total_number_of_alignments_file, frequency_of_flags_filename = delete_these_files
    outputfilename, index_outputfilename, unmapped_outputfilename, name_of_file_with_quality_scores, name_of_file_with_quality_scores_rle, name_of_file_dictionary, fclqc_output_filename = other_files
    error_file_max_input_reads, error_file_compress_, error_file_qual_rle, error_file_prep_abridge_index, error_file_7z_compression, error_file_zpaq_compression, error_file_brotli_compression, error_file_7z_decompression, error_file_zpaq_decompression, error_file_brotli_decompression, error_fclqc = error_files
    # compressed_abridged_filename_7z, compressed_abridged_filename_br,compressed_abridged_filename_zpaq = compressed_files

    if options.single_ended == True:
        ######################################################################################
        # Find maximum number of reads mapped to a single location
        # Find maximum read length
        # Find total number of alignments
        ######################################################################################

        all_commands = []
        # for input_filename in options.inputfilename:
        input_filename = options.inputfilename
        if options.quiet == False:
            logging.info( f"Starting compression for {input_filename}" )

        cmd = f"(/usr/bin/time --verbose "
        cmd += f" maxReadsMappedToSingleNucleotide  "
        cmd += f" {input_filename} "
        cmd += f" {name_of_max_input_reads_file}"
        cmd += f" {name_of_total_number_of_alignments_file} "
        cmd += f" {name_of_file_max_read_length}"
        cmd += f")"
        cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {error_file_max_input_reads}"
        else:
            cmd += f"2> /dev/null"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        all_commands.append( [cmd, "dummy"] )
        # os.system( cmd )
        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'
                )

        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'

                )

        ######################################################################################
        #  Execute the compress SAM file command for single ended reads
        ######################################################################################
        all_commands = []
        # for input_filename in options.inputfilename:
        input_filename = options.inputfilename
        if options.quiet == False:
            logging.info( f"Starting for {input_filename}" )
        max_input_reads_in_a_single_nucl_loc = int( open( name_of_max_input_reads_file, "r" ).read().strip() )
        if options.quiet == False:
            logging.info( f"{name_of_input_file_without_location} max_input_reads_in_a_single_nucl_loc = {max_input_reads_in_a_single_nucl_loc}" )

        cmd = f"(/usr/bin/time --verbose "
        cmd += f" compressSamFileSingleEnded "  # argv[0] - name of the program
        cmd += f" {options.genome}"  # argv[1] - genome_filename
        cmd += f" {options.ignore_soft_clippings}"  # argv[2]
        cmd += f" {options.ignore_mismatches} "  # argv[3]
        if options.ignore_quality_scores_for_mismatched_bases_and_soft_clips == True:
            cmd += f" 1 "  # argv[4]
        else:
            cmd += f" 0 "  # argv[4]
        cmd += f" {options.ignore_unmapped_reads} "  # argv[5]
        cmd += f" {input_filename} "  # argv[6] - Input samfile
        cmd += f" {outputfilename} "  # argv[7] - Output filename
        cmd += f" {unmapped_outputfilename} "  # argv[8] - Filename for unmapped reads
        if options.run_diagnostics == True:
            cmd += f" 1"  # argv[9] - run diagnostics
        else:
            cmd += f" 0"  # argv[9] - run diagnostics
        cmd += f" {max_input_reads_in_a_single_nucl_loc} "  # argv[10] - max_input_reads_in_a_single_nucl_loc
        cmd += f" {name_of_file_with_max_commas} "  # argv[11] - name_of_file_with_max_commas
        if options.ignore_quality_scores_for_matched_bases == True:
            cmd += f" 1 "  # argv[12]
        else:
            cmd += f" 0 "  # argv[12]
        cmd += f" {name_of_file_with_quality_scores} "  # argv[13]
        if options.ignore_alignment_scores == True:
            cmd += f" 1 "  # argv[14] - save_scores = False
        else:
            cmd += f" 0 "  # argv[14] - save_scores = True
        cmd += f" {options.output_directory}/sorted_read_names_with_NH_and_short_read_names_sorted_by_pos "  # argv[15]
        cmd += f") "
        cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {error_file_compress_}"
        else:
            cmd += f"2> /dev/null"

        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        all_commands.append( [cmd, "dummy"] )
        os.system( cmd )

        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'
                )

        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'

                )

        """
        ######################################################################################
        # Index generation
        ######################################################################################
        max_commas = int( open( name_of_file_with_max_commas, "r" ).read().strip() )
        if options.quiet == False:
            logging.info( f"{name_of_input_file_without_location} max_commas = {max_commas}" )

        cmd = f"(/usr/bin/time --verbose "
        cmd += f"buildABRIDGEIndex {outputfilename} {name_of_file_with_quality_scores} {index_outputfilename} {max_commas} 0 "
        if options.ignore_alignment_scores == True:
            cmd += f" 1 "  # argv[15] - save_scores = False
        else:
            cmd += f" 0 "  # argv[15] - save_scores = True
        cmd += f") "
        cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {error_file_prep_abridge_index}"
        else:
            cmd += f"2> /dev/null"
        if options.quiet == False:
            logging.info( f"Starting to build index for {name_of_input_file_without_location}" )
            logging.info( f"Running cmd - {cmd}" )
        all_commands.append( [cmd, "dummy"] )
        os.system( cmd )
        # pool.map(runCommand,all_commands)
        """

    else:
        # Paired ended

        ######################################################################################
        # Find maximum number of reads mapped to a single location
        # Find maximum read length
        # Find total number of alignments
        ######################################################################################
        all_commands = []
        # for input_filename in options.inputfilename:
        input_filename = options.inputfilename
        if options.quiet == False:
            logging.info( f"Starting  for {input_filename}" )

        cmd = f"(/usr/bin/time --verbose "
        cmd += f" maxReadsMappedToSingleNucleotide "
        cmd += f" {input_filename} "
        cmd += f" {name_of_max_input_reads_file} "
        cmd += f" {name_of_total_number_of_alignments_file} "
        cmd += f" {name_of_file_max_read_length} "
        cmd += f")"
        cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {error_file_max_input_reads}"
        else:
            cmd += f"2> /dev/null"
        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'
                )

        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'

                )

        all_commands = []
        # for input_filename in options.inputfilename:
        input_filename = options.inputfilename
        if options.quiet == False:
            logging.info( f"Generating for {input_filename}" )

        cmd = f" cat "
        cmd += f" {input_filename} "
        cmd += f" |grep -v ^@ "
        cmd += f" |cut -f2|uniq "
        cmd += f" |sort|uniq > {frequency_of_flags_filename}"
        all_commands.append( [cmd, "dummy"] )
        os.system( cmd )
        # pool.map(runCommand,all_commands)

        all_commands = []
        # for input_filename in options.inputfilename:
        input_filename = options.inputfilename
        if options.quiet == False:
            logging.info( f"Starting  for {input_filename}" )

        max_input_reads_in_a_single_nucl_loc = int( open( name_of_max_input_reads_file, "r" ).read().strip() )
        if options.quiet == False:
            logging.info( f"{name_of_input_file_without_location} max_input_reads_in_a_single_nucl_loc = {max_input_reads_in_a_single_nucl_loc}" )

        max_number_of_alignments = int( open( name_of_total_number_of_alignments_file, "r" ).read().strip() )
        if options.quiet == False:
            logging.info( f"{name_of_input_file_without_location} max_number_of_alignments = {max_number_of_alignments}" )

        max_read_length = int( open( name_of_file_max_read_length, "r" ).read().strip() )
        if options.quiet == False:
            logging.info( f"{name_of_input_file_without_location} max_read_length = {max_read_length}" )

        cmd = f"(/usr/bin/time --verbose "
        cmd += f" compressSamFilePairedEnded"  # argv[0] - name of the program
        cmd += f" {options.genome}"  # argv[1] - genome_filename
        cmd += f" {options.ignore_soft_clippings}"  # argv[2]
        cmd += f" {options.ignore_mismatches} "  # argv[3]
        if options.ignore_quality_scores_for_mismatched_bases_and_soft_clips == True:
            cmd += f" 1 "  # argv[4]
        else:
            cmd += f" 0 "  # argv[4]
        cmd += f" {options.ignore_unmapped_reads} "  # argv[5]
        cmd += f" {input_filename} "  # argv[6] - Input samfile
        cmd += f" {outputfilename} "  # argv[7] - Output filename
        cmd += f" {unmapped_outputfilename} "  # argv[8] - Filename for unmapped reads
        if options.run_diagnostics == True:
            cmd += f" 1"  # argv[9] - run diagnostics
        else:
            cmd += f" 0"  # argv[9] - run diagnostics
        cmd += f" {max_input_reads_in_a_single_nucl_loc} "  # argv[10] - max_input_reads_in_a_single_nucl_loc
        cmd += f" {name_of_file_with_max_commas} "  # argv[11] - name_of_file_with_max_commas
        if options.ignore_quality_scores_for_matched_bases == True:
            cmd += f" 1 "  # argv[12]
        else:
            cmd += f" 0 "  # argv[12]
        cmd += f" {name_of_file_with_quality_scores} "  # argv[13]
        cmd += f" {max_number_of_alignments} "  # argv[14]
        cmd += f" {max_read_length} "  # argv[15]
        cmd += f" {frequency_of_flags_filename} "  # argv[16]
        cmd += f" {name_of_file_dictionary} "  # argv[17]
        if options.ignore_alignment_scores == True:
            cmd += f" 1 "  # argv[18] - save_scores = False
        else:
            cmd += f" 0 "  # argv[18] - save_scores = True
        cmd += f" {options.output_directory}/sorted_read_names_with_NH_and_short_read_names_sorted_by_pos "  # argv[19]
        cmd += f") "
        # cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {error_file_compress_}"
        else:
            cmd += f"2> /dev/null"

        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'
                )

        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'

                )
        """
        ######################################################################################
        # Index generation
        ######################################################################################
        max_commas = int( open( name_of_file_with_max_commas, "r" ).read().strip() )
        if options.quiet == False:
            logging.info( f"{name_of_input_file_without_location} max_commas = {max_commas}" )

        cmd = f"(/usr/bin/time --verbose "
        cmd += f"{buildABRIDGEIndex} {outputfilename} {name_of_file_with_quality_scores} {index_outputfilename} {max_commas} 1 "
        if options.ignore_alignment_scores == True:
            cmd += f" 1 "
        else:
            cmd += f" 0 "
        cmd += f") "
        cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {error_file_prep_abridge_index}"
        else:
            cmd += f"2> /dev/null"
        if options.quiet == False:
            logging.info( f"Starting to build index for {name_of_input_file_without_location}" )
            logging.info( f"Running cmd - {cmd}" )
        all_commands.append( [cmd, "dummy"] )
        os.system( cmd )
        # pool.map(runCommand,all_commands)
        """

    ######################################################################################
    # Compress Qualtiy scores file
    ######################################################################################
    number_of_quality_scores = int( open( f"{name_of_total_number_of_alignments_file}" , "r" ).read().strip() )

    # Create the parameter file for fclqc
    fhw = open( f"{options.output_directory}/parameter.json", "w" )
    fhw.write( "{\n" )
    fhw.write( f"\t\"precision\": 52,\n" )
    fhw.write( f"\t\"file_size\": {number_of_quality_scores},\n" )
    fhw.write( f"\t\"thread_num\": {options.cpu},\n" )
    fhw.write( f"\t\"first_line\": 1,\n" )
    fhw.write( f"\t\"last_line\": {number_of_quality_scores*4}\n" )
    fhw.write( "}\n" )
    fhw.close()

    cmd = f"(/usr/bin/time --verbose "
    cmd += f" main "
    cmd += f" -c {name_of_file_with_quality_scores} "
    cmd += f" {fclqc_output_filename}"
    cmd += f" {options.output_directory}/parameter.json"
    cmd += f") "
    cmd += f" 1> /dev/null "
    cmd += f" 2> {error_fclqc}"

    if options.framework == "docker":
        runDockerCommand( logging,
                          name = "fclqc",
                            version = list_of_softwares_with_versions['fclqc'],
                            image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/fclqc",
                            container_name = f"{options.output_directory.split('/')[-1]}",
                            volumes = volumes_list,
                            command = cmd,
                            cpus = options.cpu,
                            memory = '100g'
            )

    elif options.framework == "singularity":
        runSingularityCommand( logging,
                            name = "fclqc",
                            version = list_of_softwares_with_versions['fclqc'],
                            image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/fclqc",
                            container_name = f"{options.output_directory.split('/')[-1]}",
                            volumes = volumes_list,
                            command = cmd,
                            cpus = options.cpu,
                            memory = '100g'

            )

    ######################################################################################
    # Generate SHA512 for genome file
    ######################################################################################
    reference_sha512_filename = f"{options.output_directory}/reference_sha512"
    cmd = f"sha512sum {options.genome} > {reference_sha512_filename}.temp"
    os.system( cmd )
    open( reference_sha512_filename, "w" ).write( open( f"{reference_sha512_filename}.temp", "r" ).read().strip().split()[0] )
    os.system( f"rm {reference_sha512_filename}.temp" )

    ######################################################################################
    # Compress files
    ######################################################################################

    if options.quiet == False:
        logging.info( "Starting compression with zpaq" )

    fclqc_output_filename = f"{fclqc_output_filename}001.enc"
    cmd = f"(/usr/bin/time --verbose "
    cmd += f" zpaq a "
    cmd += f" {options.outputfilename} "  # Final name of the compressed file ending in .abridge
    cmd += f" {outputfilename} "  # The non redundant version of the sam file
    cmd += f" {unmapped_outputfilename} "  # Set of unmapped reads
    cmd += f" {reference_sha512_filename} "  # The 128 bit hash of the reference
    cmd += f" {fclqc_output_filename} "  # FCLQC compressed quality scores file
    if options.single_ended == False:
        cmd += f" {name_of_file_dictionary} "
    cmd += f" {name_of_file_with_quality_scores} "
    cmd += f" -m3 -t{options.cpu} -f "
    cmd += f" -noattributes "
    cmd += f") "
    cmd += f"1> /dev/null "
    if options.keep_intermediate_error_files == True:
        cmd += f"2> {error_file_zpaq_compression}"
    else:
        cmd += f"2> /dev/null"

    if options.framework == "docker":
        runDockerCommand( logging,
                          name = "zpaq",
                            version = list_of_softwares_with_versions['zpaq'],
                            image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/zpaq",
                            container_name = f"{options.output_directory.split('/')[-1]}",
                            volumes = volumes_list,
                            command = cmd,
                            cpus = options.cpu,
                            memory = '100g'
            )

    elif options.framework == "singularity":
        runSingularityCommand( logging,
                            name = "zpaq",
                            version = list_of_softwares_with_versions['zpaq'],
                            image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/zpaq",
                            container_name = f"{options.output_directory.split('/')[-1]}",
                            volumes = volumes_list,
                            command = cmd,
                            cpus = options.cpu,
                            memory = '100g'

            )

    all_files = glob.glob( f"{options.output_directory}/*" )
    keep_these_files = []
    for file in all_files:
        if file[-6:] == ".error" or file[-8:] == ".abridge":
            keep_these_files.append( file )
    remove_these_files = list( set( all_files ) - set( keep_these_files ) )

    if options.preserve_all_intermediate_files == False:
        for file in remove_these_files:
            os.system( "rm -rf " + file )


def findEndedness( options, logging ):
    """
    """
    endedness = []
    fhr = open( f"{options.inputfilename}", "r" )
    for line in fhr:
        if line[0] != '@':
            samformatflag = int( line.strip().split()[1] )
            endedness.append( samformatflag % 2 )
            break

    if len( set( endedness ) ) != 1:
        print( "A mixture of single and paired ended files is not allowed. Exiting..." )
        if options.quiet == False:
            logging.info( "A mixture of single and paired ended files is not allowed. Exiting..." )

    if endedness[0] == 0:
        options.single_ended = True
    else:
        options.single_ended = False


def collectReferenceSequenceNameAndLength( options, logging ):
    """
    """
    reference_to_length = {}
    fhr = open( f"{options.inputfilename[0][:-3]}header", "r" )
    for line in fhr:
        if line[:3] == "@SQ":
            useless, reference_name, reference_length = line.strip().split( "\t" )
            reference_name = reference_name.split( ":" )[-1]
            reference_length = int( reference_length.split( ":" )[-1] )
            reference_to_length[reference_name] = reference_length
    fhr.close()
    options.reference_to_length = reference_to_length


def findChromosomes( filename ):
    chromosomes = []
    fhr = open( filename, "r" )
    for line_num, line in enumerate( fhr ):
        if line_num == 0:continue
        chromosomes.append( line.split()[0] )
    fhr.close()
    return list( set( chromosomes ) )


def mergeAbridgeData( options ):
    pool = multiprocessing.Pool( processes = int( options.cpu ) )

    cmd = f"samtools faidx {options.genome}"
    if os.path.exists( f"{options.genome}.fai" ) == False:
        if options.quiet == False:
            logging.info( f"Running cmd - {cmd}" )
        os.system( cmd )

    files_to_be_removed = []
    all_commands = []
    for input_filename in options.inputabrfilename:
        input_filename_without_extension = input_filename.split( "/" )[-1][:-11]
        _filename = options.output_directory + "/" + input_filename_without_extension + "."
        _index_filename = options.output_directory + "/" + input_filename_without_extension + "..index"
        unmapped_outputfilename = options.output_directory + "/" + input_filename_without_extension + ".unmapped"
        compressed_abridged_filename = input_filename

        cmd = f"7za e {input_filename} -y"
        cmd += f" -o{options.output_directory}"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        all_commands.append( [cmd, "dummy"] )

        files_to_be_removed.extend( [input_filename_without_extension,
                                    _filename,
                                    _index_filename,
                                    unmapped_outputfilename] )
    pool.map( runCommand, all_commands )

    ######################################################################################
    # Compiling programs - will be removed during final version
    ######################################################################################
    mergeCompressedFilesSingleEnded = options.softwares["mergeCompressedFilesSingleEnded"]
    cmd = f"gcc -o {mergeCompressedFilesSingleEnded} {mergeCompressedFilesSingleEnded}.c -g -Ofast"
    os.system( cmd )

    # addTagToSamFile = options.softwares["addTagToSamFile"]
    # cmd=f"gcc -o {addTagToSamFile} {addTagToSamFile}.c -g -Ofast"
    # os.system(cmd)
    ######################################################################################

    # Compile a list of all chromosomes in all the files to be merged
    all_chromosomes = []
    for input_filename in options.inputabrfilename:
        input_filename_without_extension = input_filename.split( "/" )[-1][:-11]
        _index_filename = options.output_directory + "/" + input_filename_without_extension + "..index"
        all_chromosomes.extend( findChromosomes( _index_filename ) )
    all_chromosomes = list( set( all_chromosomes ) )
    all_chromosomes = sorted( all_chromosomes )
    """print(all_chromosomes)
    sys.stdout.flush()"""

    all_commands = []
    for chromosome in all_chromosomes:
        merged_output_filename = options.output_directory + "/" + options.output_directory.split( "/" )[-1] + ".merged." + chromosome
        cmd = mergeCompressedFilesSingleEnded
        for input_filename in options.inputabrfilename:
            input_filename_without_extension = input_filename.split( "/" )[-1][:-11]
            _filename = options.output_directory + "/" + input_filename_without_extension + "."
            _index_filename = options.output_directory + "/" + input_filename_without_extension + "..index"
            unmapped_outputfilename = options.output_directory + "/" + input_filename_without_extension + ".unmapped"
            compressed_abridged_filename = input_filename

            cmd += " " + _filename
        cmd += " " + merged_output_filename
        cmd += " " + chromosome
        all_commands.append( [cmd, "dummy"] )
        if options.quiet == False:
            logging.info( f"Running cmd - {cmd}" )
        ######################################################################################
        # Running in single core mode
        ######################################################################################
        # os.system(cmd)
    pool.map( runCommand, all_commands )

    for chromosome in all_chromosomes:
        cmd = "cat "
        cmd += options.output_directory + "/" + options.output_directory.split( "/" )[-1] + ".merged." + chromosome + ">> "
        cmd += " " + options.output_directory + "/" + options.output_directory.split( "/" )[-1] + ".merged"
        os.system( cmd )

        os.system( "rm -f " + options.output_directory + "/" + options.output_directory.split( "/" )[-1] + ".merged." + chromosome )

    for file in files_to_be_removed:
        os.system( "rm " + file )


def decompressSamFile( options ):
    """
    """
    pool = multiprocessing.Pool( processes = int( options.cpu ) )

    input_filename = options.inputabrfilename[:-8] + ".sam"
    name_of_input_file_without_location = input_filename.split( "/" )[-1]
    delete_these_files, other_files, error_files = constructFileNames( input_filename, options )
    name_of_max_input_reads_file, name_of_file_with_max_commas, name_of_file_max_read_length, name_of_total_number_of_alignments_file, frequency_of_flags_filename = delete_these_files
    _outputfilename, _index_outputfilename, unmapped_outputfilename, name_of_file_with_quality_scores, name_of_file_with_quality_scores_rle, name_of_file_dictionary = other_files
    error_file_max_input_reads, error_file_compress_, error_file_qual_rle, error_file_prep_abridge_index, error_file_7z_compression, error_file_zpaq_compression, error_file_brotli_compression, error_file_7z_decompression, error_file_zpaq_decompression, error_file_brotli_decompression = error_files

    cmd = f"samtools faidx {options.genome}"
    if os.path.exists( f"{options.genome}.fai" ) == False:
        if options.quiet == False:
            logging.info( f"Running cmd - {cmd}" )
        os.system( cmd )

    decompressSamFileSingleEnded = options.softwares["decompressSamFileSingleEnded"]
    decompressSamFilePairedEnded = options.softwares["decompressSamFilePairedEnded"]
    deCompressQualityScoresFile = options.softwares["deCompressQualityScoresFile"]
    maxReadsInEachLine = options.softwares["maxReadsInEachLine"]
    ######################################################################################
    # Compiling programs - will be removed during final version
    ######################################################################################
    if options.compile_programs == True:
        cmd = f"gcc {decompressSamFileSingleEnded}.c -o {decompressSamFileSingleEnded} -Ofast"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )

        cmd = f"gcc {decompressSamFilePairedEnded}.c -o {decompressSamFilePairedEnded} -Ofast"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )

        cmd = f"gcc {deCompressQualityScoresFile}.c -o {deCompressQualityScoresFile} -Ofast"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )

        cmd = f"gcc {maxReadsInEachLine}.c -o {maxReadsInEachLine} -Ofast"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )
    ######################################################################################

    # Check the amount memory needed
    if options.ignore_sequence == 0:
        assessMemoryRequirement( f"{options.genome}.fai", options )

    files_to_be_removed = []

    # Use 7za to unpack the single compressed file
    cmd = f"7za e {options.inputabrfilename} -y -mmt={options.cpu} "
    cmd += f" -o{options.output_directory}"
    cmd += f" 1> /dev/null 2>/dev/null"
    if options.quiet == False:
        logging.info( f"Running command - {cmd}" )
    os.system( cmd )
    time.sleep( 1 )

    compressor = open( f"{options.output_directory}/compression_method", "r" ).read()
    if compressor == "brotli":
        cmd = f"brotli -d -k -f "
        cmd += f"{_outputfilename}.br "
        cmd += f"{_index_outputfilename}.br "
        cmd += f"{unmapped_outputfilename}.br "
        if os.path.exists( f"{name_of_file_with_quality_scores_rle}.br" ) == True:
            cmd += f"{name_of_file_with_quality_scores_rle}.br "
        if os.path.exists( f"{name_of_file_with_quality_scores}.br" ) == True:
            cmd += f"{name_of_file_with_quality_scores}.br "
        if os.path.exists( f"{name_of_file_dictionary}.br" ) == True:
            cmd += f"{name_of_file_dictionary}.br "
        files_to_be_removed.extend( f"{_outputfilename}.br {_index_outputfilename}.br {unmapped_outputfilename}.br {name_of_file_with_quality_scores}.rle.br".split() )
        os.system( cmd )
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
    elif compressor == "7z":
        # No need to decompress further
        pass
    elif compressor == "zpaq":
        filename = options.inputabrfilename.split( "/" )[-1]
        zpaq = " zpaq "
        cmd = f"{zpaq} l {options.output_directory}/{filename}.zpaq > {options.output_directory}/file_list  2> /dev/null"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )
        fhr = open( f"{options.output_directory}/file_list", "r" )
        line_num = 0
        for line in fhr:
            line_num += 1
            if line_num == 4:
                compression_directory = "/".join( line.strip().split()[-1].split( "/" )[:-1] )
                break

        # compression_directory = compression_directory.split("/")[-2]
        fhr.close()
        cmd = f"{zpaq} x {options.output_directory}/{filename}.zpaq {'/'.join(compression_directory.split('/')[:-1])} -to {options.output_directory} -t{options.cpu} 2> /dev/null"
        os.system( cmd )
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )

        # Move files
        cmd = f"mv {options.output_directory}/{compression_directory.split('/')[-1]}/* {options.output_directory}"
        os.system( cmd )
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        files_to_be_removed.append( f"{options.output_directory}/{compression_directory.split('/')[-1]}" )

    files_to_be_removed.extend( [_outputfilename,
                                _index_outputfilename,
                                unmapped_outputfilename,
                                name_of_file_with_quality_scores,
                                f"{name_of_file_with_quality_scores}.rle",
                                f"{options.output_directory}/file_list"] )

    flag_ignore_mismatches, flag_ignore_soft_clippings, flag_ignore_unmapped_sequences, flag_ignore_quality_score, ignore_quality_scores_for_matched_bases, save_exact_quality_scores, ignore_alignment_scores = list( map( int, open( _outputfilename, "rb" ).readline().split() ) )
    if flag_ignore_mismatches == 1:
        options.ignore_mismatches = True
    else:
        options.ignore_mismatches = False
    if flag_ignore_soft_clippings == 1:
        options.ignore_soft_clippings = True
    else:
        options.ignore_soft_clippings = False
    if flag_ignore_unmapped_sequences == 1:
        options.ignore_unmapped_sequences = True
    else:
        options.ignore_unmapped_sequences = False
    if flag_ignore_quality_score == 1:
        options.ignore_quality_score = True
    else:
        options.ignore_quality_score = False
    if ignore_quality_scores_for_matched_bases == 1:
        options.ignore_quality_scores_for_matched_bases = True
    else:
        options.ignore_quality_scores_for_matched_bases = False
    if save_exact_quality_scores == 1:
        options.save_exact_quality_scores = True
    else:
        options.save_exact_quality_scores = False
    if ignore_alignment_scores == 1:
        options.ignore_alignment_scores = True
    else:
        options.ignore_alignment_scores = False

    ######################################################################################
    # Convert RLE back to quality scores
    ######################################################################################
    if options.ignore_quality_scores_for_matched_bases == True and options.save_exact_quality_scores == False:
        cmd = f"(/usr/bin/time --verbose "
        cmd += f" {deCompressQualityScoresFile} "
        cmd += f" {name_of_file_with_quality_scores_rle} "
        cmd += f" {name_of_file_with_quality_scores} "
        cmd += f") "
        cmd += f"1> /dev/null "
        if options.keep_intermediate_error_files == True:
            cmd += f"2> {options.error_directory}/{name_of_input_file_without_location}_RLE_decompress.error"
        else:
            cmd += f"2> /dev/null"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )
    elif options.ignore_quality_scores_for_matched_bases == False and options.save_exact_quality_scores == False:
        cmd = f"touch {name_of_file_with_quality_scores}"
        os.system( cmd )

    max_reads_in_each_line_filename = f"{options.output_directory}/max_reads_in_each_line_filename"
    output_sam_filename = f"{options.output_directory}/{name_of_input_file_without_location[:-4]}.decompressed.sam"
    files_to_be_removed.extend( [_index_outputfilename,
                                _outputfilename,
                                unmapped_outputfilename,
                                name_of_file_with_quality_scores,
                                name_of_file_dictionary,
                                max_reads_in_each_line_filename] )

    cmd = f"(/usr/bin/time --verbose "
    if os.path.exists( name_of_file_dictionary ) == False:
        cmd += f" {decompressSamFileSingleEnded} "  # argv[0] - Name of the program
    else:
        cmd += f" {decompressSamFilePairedEnded} "  # argv[0] - Name of the program
    cmd += f" {_index_outputfilename} "  # argv[1] - Abridge index, _index_outputfilename
    cmd += f" {options.genome} "  # argv[2] - genome file
    cmd += f" {output_sam_filename} "  # argv[3] - decompressed SAM filename
    cmd += f" {_outputfilename} "  # argv[4] - Name of the  filename
    cmd += f" dummy "  # argv[5] - Dummy
    cmd += f" {options.quality} "  # argv[6] - Quality of reads
    cmd += f" {options.ignore_sequence}"  # argv[7] - Whether or not to produce sequences from genome file
    cmd += f" {unmapped_outputfilename}"  # argv[8] - Name of file with unmapped reads
    cmd += f" {name_of_file_with_quality_scores} "  # argv[9] - Name of file with quality scores
    if os.path.exists( name_of_file_dictionary ) == True:
        cmd += f" {name_of_file_dictionary} "  # argv[10]

        cmd_1 = f" {maxReadsInEachLine} "
        cmd_1 += f" {_outputfilename} "
        cmd_1 += f" {max_reads_in_each_line_filename} "
        if options.quiet == False:
            logging.info( f"Running command - {cmd_1}" )
        os.system( cmd_1 )

        max_reads_in_each_line = open( max_reads_in_each_line_filename, "r" ).readline().strip()
        cmd += f" {max_reads_in_each_line} "  # argv[11]
    cmd += f") "
    # cmd += f"1> /dev/null "
    if options.keep_intermediate_error_files == True:
        cmd += f"2> {options.error_directory}/{name_of_input_file_without_location}_decompress.error"
    else:
        cmd += f"2> /dev/null"
    if options.quiet == False:
        logging.info( f"Running command - {cmd}" )
    os.system( cmd )

    for file in files_to_be_removed:
        if options.quiet == False:
            logging.info( f"Deleting - {file}" )
        os.system( "rm -rf " + file )


def generateCoverage( _outputfilename, _index_outputfilename, options ):
    generateCoverage = options.softwares["generateCoverage"]
    findMaximumNumberOfReadsInEachLine = options.softwares["findMaximumNumberOfReadsInEachLine"]

    ######################################################################################
    # Compiling programs - will be removed during final version
    ######################################################################################
    if options.compile_programs == True:
        cmd = f"gcc {generateCoverage}.c -o {generateCoverage} -g -Ofast"
        os.system( cmd )

        cmd = f"gcc {findMaximumNumberOfReadsInEachLine}.c -o {findMaximumNumberOfReadsInEachLine} -g -Ofast"
        os.system( cmd )
    ######################################################################################
    if options.d == True:
        options.d = 1
    else:
        options.d = 0
    if options.bg == True:
        options.bg = 1
    else:
        options.bg = 0
    if options.bga == True:
        options.bga = 1
    else:
        options.bga = 0
    if options.split == True:
        options.split = 1
    else:
        options.split = 0
    if options.generate_overlapping_coverage == True:
        options.generate_overlapping_coverage = 1
    else:
        options.generate_overlapping_coverage = 0
    if options.generate_non_overlapping_coverage == True:
        options.generate_non_overlapping_coverage = 1
    else:
        options.generate_non_overlapping_coverage = 0

    name_of_input_file_without_location = options.inputabrfilename.split( "/" )[-1].split( ".abridge" )[0]
    dictionary_name = f"{options.output_directory}/{name_of_input_file_without_location}.sam.dictionary"
    if os.path.exists( dictionary_name ) == True:
        single = 0
    else:
        single = 1

    max_reads_in_each_line_filename = f"{options.output_directory}/{name_of_input_file_without_location}.max_read_in_each_line"

    cmd = f"(/usr/bin/time --verbose "
    cmd += f" {generateCoverage} "
    cmd += f" {_outputfilename} "  # argv[1]
    cmd += f" {_index_outputfilename} "  # argv[2]
    cmd += f" {options.d} "  # argv[3]
    cmd += f" {options.bg} "  # argv[4]
    cmd += f" {options.bga} "  # argv[5]
    cmd += f" {options.split} "  # argv[6]
    cmd += f" {options.generate_overlapping_coverage} "  # argv[7]
    cmd += f" {options.generate_non_overlapping_coverage} "  # argv[8]
    cmd += f" {single} "  # argv[9]
    if os.path.exists( dictionary_name ) == True:
        cmd += f" {dictionary_name} "  # argv[10]
        cmd_1 = f" {findMaximumNumberOfReadsInEachLine} "
        cmd_1 += f" {_outputfilename} "
        cmd_1 += f" 1> {max_reads_in_each_line_filename} "
        cmd_1 += f" 2> /dev/null "
        if options.quiet == False:
            logging.info( f"Running command - {cmd_1}" )
        os.system( cmd_1 )
        max_reads_in_each_line = open( max_reads_in_each_line_filename, "r" ).readline().strip()
        cmd += f" {max_reads_in_each_line} "  # argv[11]
    cmd += f") "
    if options.keep_intermediate_error_files == True:
        # cmd += f" 1> {options.error_directory}/{name_of_input_file_without_location}_coverage_generation_{options.d}_{options.bg}_{options.bga}_{options.split}_{options.generate_overlapping_coverage}_{options.generate_non_overlapping_coverage}.output "
        cmd += f" 2> {options.error_directory}/{name_of_input_file_without_location}_coverage_generation_{options.d}_{options.bg}_{options.bga}_{options.split}_{options.generate_overlapping_coverage}_{options.generate_non_overlapping_coverage}.error"
    else:
        # cmd += f" 1> /dev/null "
        cmd += f"2> /dev/null"
    if options.quiet == False:
        logging.info( f"Running command - {cmd}" )
    print( cmd )
    os.system( cmd )


def retrieveAlignmentsRandomly( chromosome, start, end, options ):

    randomRetrievalSingleEnded = options.softwares["randomRetrievalSingleEnded"]
    randomRetrievalPairedEnded = options.softwares["randomRetrievalPairedEnded"]
    deCompressQualityScoresFile = options.softwares["deCompressQualityScoresFile"]
    ######################################################################################
    # Compiling programs - will be removed during final version
    ######################################################################################
    if options.compile_programs == True:
        cmd = f"gcc {randomRetrievalSingleEnded}.c -o {randomRetrievalSingleEnded} -g -Ofast"
        os.system( cmd )
        cmd = f"gcc {randomRetrievalPairedEnded}.c -o {randomRetrievalPairedEnded} -g -Ofast"
        os.system( cmd )
        cmd = f"gcc {deCompressQualityScoresFile}.c -o {deCompressQualityScoresFile} -Ofast"
        os.system( cmd )
    ######################################################################################

    genome_filename = options.genome
    genome_index_filename = options.genome + ".fai"

    input_filename = options.inputabrfilename
    name_of_input_file_without_location = input_filename.split( "/" )[-1][:-8]
    _outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise"
    _index_outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise_index"
    unmapped_outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_conciseunmapped"
    name_of_file_with_quality_scores = f"{options.output_directory}/{name_of_input_file_without_location}.sam_concisequal"
    compressed_abridged_filename = input_filename
    output_sam_filename = options.output_directory + "/" + name_of_input_file_without_location + ".decompressed.sam"
    outputfilename = options.output_directory + "/" + name_of_input_file_without_location + "_" + options.positions.replace( ":", "_" ) + ".sam"
    files_to_be_removed = []

    cmd = f"(/usr/bin/time --verbose "
    cmd += f" {deCompressQualityScoresFile} "
    cmd += f" {name_of_file_with_quality_scores}.rle "
    cmd += f" {name_of_file_with_quality_scores} "
    cmd += f") "
    cmd += f"1> /dev/null "
    if options.keep_intermediate_error_files == True:
        cmd += f"2> {options.error_directory}/{name_of_input_file_without_location}_RLE_decompress.error"
    else:
        cmd += f"2> /dev/null"
    os.system( cmd )
    files_to_be_removed.append( f"{name_of_file_with_quality_scores}" )

    dictionary_name = f"{options.output_directory}/{name_of_input_file_without_location}.sam.dictionary"
    # print(dictionary_name)
    if os.path.exists( dictionary_name ) == False:
        cmd = f" {randomRetrievalSingleEnded} "  # argv[0]
    else:
        cmd = f" {randomRetrievalPairedEnded} "  # argv[0]
    cmd += f" {_index_outputfilename} "  # argv[1]
    cmd += f" {genome_filename} "  # argv[2]
    cmd += f" {genome_index_filename} "  # argv[3]
    cmd += f" {chromosome} "  # argv[4]
    cmd += f" {_outputfilename}  "  # argv[5]
    cmd += f" {start} "  # argv[6]
    cmd += f" {end} "  # argv[7]
    cmd += f" {outputfilename}"  # argv[8]
    cmd += f" {options.quality}"  # argv[9[
    cmd += f" {options.ignore_sequence}"  # argv[10]
    if options.read_prefix is not None:
        cmd += f" {options.read_prefix}"  # argv[11]
    else:
        cmd += f" \"\" "  # argv[11]
    cmd += f" {name_of_file_with_quality_scores}"  # argv[12]
    if os.path.exists( dictionary_name ) == True:
        cmd += f" {dictionary_name} "  # argv[13]
    # print(cmd)
    # sys.stdout.flush()
    os.system( cmd )


def prepareInputFilesForCompressing( options, list_of_softwares_with_versions, remove_these_files, volumes_list, logging ):
    """
    Performs the following operations:
    - Checks if the input file is a bamfile or samfile
    - Prepares a samfile coordinate sorted
    """

    file_extension = options.inputfilename[-3:]
    if file_extension == "bam":
        cmd = f"samtools view -h -@ {options.cpu} {options.inputfilename}|head > {options.output_directory}/header"
        remove_these_files.append( f"{options.output_directory}/header" )

        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "samtools",
                                version = list_of_softwares_with_versions['samtools'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '1g'
                )
        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                   name = "samtools",
                                version = list_of_softwares_with_versions['samtools'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '1g'
                                )

        first_line = open( f"{options.output_directory}/header" , "r" ).readline().strip()
        if "SO:coordinate" in first_line:
            # Convert to Sam file
            cmd = f"samtools view -h -@ {options.cpu} {options.inputfilename} > {options.output_directory}/inputfilename.sam "
            options.inputfilename = f"{options.output_directory}/inputfilename.sam"
            remove_these_files.append( options.inputfilename )

            if os.path.exists( f"{options.output_directory}/inputfilename.sam" ) == True:return
            if options.framework == "docker":
                runDockerCommand( logging,
                                  name = "samtools",
                                    version = list_of_softwares_with_versions['samtools'],
                                    image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                    container_name = f"{options.output_directory.split('/')[-1]}",
                                    volumes = volumes_list,
                                    command = cmd,
                                    cpus = options.cpu,
                                    memory = '100g'
                    )

            elif options.framework == "singularity":
                runSingularityCommand( logging,
                                       name = "samtools",
                                    version = list_of_softwares_with_versions['samtools'],
                                    image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                    container_name = f"{options.output_directory.split('/')[-1]}",
                                    volumes = volumes_list,
                                    command = cmd,
                                    cpus = options.cpu,
                                    memory = '100g'
                                    )
        else:
            # Need to sort by coordinate
            cmd = f"samtools sort -@ {options.cpu} {options.inputfilename}|samtools view -h -@ {options.cpu} > {options.output_directory}/inputfilename.sam "
            options.inputfilename = f"{options.output_directory}/inputfilename.sam"
            remove_these_files.append( options.inputfilename )

            if os.path.exists( f"{options.output_directory}/inputfilename.sam" ) == True:return
            if options.framework == "docker":
                runDockerCommand( logging,
                                    name = "samtools",
                                    version = list_of_softwares_with_versions['samtools'],
                                    image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                    container_name = f"{options.output_directory.split('/')[-1]}",
                                    volumes = volumes_list,
                                    command = cmd,
                                    cpus = options.cpu,
                                    memory = '100g'
                    )

            elif options.framework == "singularity":
                runSingularityCommand( logging,
                                    name = "samtools",
                                    version = list_of_softwares_with_versions['samtools'],
                                    image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                    container_name = f"{options.output_directory.split('/')[-1]}",
                                    volumes = volumes_list,
                                    command = cmd,
                                    cpus = options.cpu,
                                    memory = '100g'
                    )

    elif file_extension == "sam":
        first_line = open( options.inputfilename, "r" ).readline().strip()
        if "SO:coordinate" in first_line:
            # Nothing to change
            pass
        else:
            # Sort Samfile by coordinate
            cmd = f"samtools view -bS -@ {options.cpu} {options.inputfilename}|samtools sort -@ {options.cpu}|samtools view -h -@ {options.cpu} > {options.output_directory}/inputfilename.sam "
            options.inputfilename = f"{options.output_directory}/inputfilename.sam"
            remove_these_files.append( options.inputfilename )

            if os.path.exists( f"{options.output_directory}/inputfilename.sam" ) == True:return
            if options.framework == "docker":
                runDockerCommand( logging,
                                  name = "samtools",
                                    version = list_of_softwares_with_versions['samtools'],
                                    image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                    container_name = f"{options.output_directory.split('/')[-1]}",
                                    volumes = volumes_list,
                                    command = cmd,
                                    cpus = options.cpu,
                                    memory = '100g'
                    )

            elif options.framework == "singularity":
                runSingularityCommand( logging,
                                    name = "samtools",
                                    version = list_of_softwares_with_versions['samtools'],
                                    image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                    container_name = f"{options.output_directory.split('/')[-1]}",
                                    volumes = volumes_list,
                                    command = cmd,
                                    cpus = options.cpu,
                                    memory = '100g'

                    )


def alterReadNamesAndAddNHTag( options, logging, list_of_softwares_with_versions, volumes_list , remove_these_files ):
    """
    """
    cmd = f"cat {options.inputfilename}|grep -v ^@|cut -f1|awk -vOFS=\"\\t\" " + "'{print $0,NR}'|sort "
    cmd += f"> {options.output_directory}/sorted_read_names"
    if os.path.exists( f"{options.output_directory}/sorted_read_names" ) == False:
        os.system( cmd )
    remove_these_files.append( f"{options.output_directory}/sorted_read_names" )
    logging.info( "Read names sorted" )

    cmd = f"cat {options.output_directory}/sorted_read_names" + "|cut -f1|uniq -c|awk -vOFS=\"\\t\" '{print $2,$1}'"
    cmd += f"> {options.output_directory}/NH_vals"
    if os.path.exists( f"{options.output_directory}/NH_vals" ) == False:
        os.system( cmd )
    remove_these_files.append( f"{options.output_directory}/NH_vals" )
    logging.info( "" )

    cmd = f"join {options.output_directory}/sorted_read_names {options.output_directory}/NH_vals" + " |awk -vOFS=\"\\t\" '{print $1,$2,$3}' "
    cmd += f" > {options.output_directory}/sorted_read_names_with_NH"
    if os.path.exists( f"{options.output_directory}/sorted_read_names_with_NH" ) == False:
        os.system( cmd )
    remove_these_files.append( f"{options.output_directory}/sorted_read_names_with_NH" )
    logging.info( "" )

    cmd = f"associateShortNamesToReads {options.output_directory}/sorted_read_names_with_NH {options.output_directory}/sorted_read_names_with_NH_and_short_read_names "
    if os.path.exists( f"{options.output_directory}/sorted_read_names_with_NH_and_short_read_names" ) == False:
        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'
                )

        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                name = "abridge",
                                version = list_of_softwares_with_versions['abridge'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/abridge",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'

                )
    remove_these_files.append( f"{options.output_directory}/sorted_read_names_with_NH_and_short_read_names" )
    logging.info( "" )

    cmd = f"sort -nk2,2 {options.output_directory}/sorted_read_names_with_NH_and_short_read_names "
    cmd += f" > {options.output_directory}/sorted_read_names_with_NH_and_short_read_names_sorted_by_pos"
    if os.path.exists( f"{options.output_directory}/sorted_read_names_with_NH_and_short_read_names_sorted_by_pos" ) == False:
        os.system( cmd )
    remove_these_files.append( f"{options.output_directory}/sorted_read_names_with_NH_and_short_read_names_sorted_by_pos" )
    logging.info( "" )


def main():
    commandLineArg = sys.argv
    if len( commandLineArg ) == 1:
        print( "Please use the --help option to get usage information" )
    options = parseCommandLineArguments()
    validateCommandLineArguments( options )
    if options.force == True:
        os.system( f"rm -rf {options.output_directory}" )
    os.system( f"mkdir -p {options.output_directory}/singularity_images" )
    os.system( f"which docker > {options.output_directory}/find_docker" )
    os.system( f"which singularity > {options.output_directory}/find_singularity" )
    if options.logfilename is None:
        options.logfilename = f"{options.output_directory}/progress.log"

    if options.quiet == False:
        configureLogger( options )
    if options.quiet == False:
        logging.info( "Logger has been configured" )
    if options.quiet == False:
        logging.info( "validateCommandLineArguments() execution is complete" )

    remove_these_files = []

    if options.error_directory is None:
        options.error_directory = options.output_directory

    genome_filename_without_location = options.genome.split( "/" )[-1]
    if os.path.exists( f"{options.output_directory}/{genome_filename_without_location}" ) == False:
        cmd = f"perl -pe '/^>/ ? print \"\\n\" : chomp' {options.genome} | tail -n +2 > {options.output_directory}/{genome_filename_without_location}"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )
    options.genome = f"{options.output_directory}/{genome_filename_without_location}"

    volumes_list = [f"{'/'.join(options.genome.split('/')[:-1])}:{'/'.join(options.genome.split('/')[:-1])}",
                    f"{options.output_directory}:{options.output_directory}",
                    f"{options.error_directory}:{options.error_directory}",
                    f"{'/'.join(options.inputfilename.split('/')[:-1])}:{'/'.join(options.inputfilename.split('/')[:-1])}",
                    ]

    docker_installed = 1 if "Command not found" not in open( f"{options.output_directory}/find_docker", "r" ).read() else 0
    singularity_installed = 1 if "Command not found" not in open( f"{options.output_directory}/find_singularity", "r" ).read() else 0

    if docker_installed == 0 and singularity_installed == 0:
        print( "You need to have either docker or singularity installed" )
        sys.exit()

    framework_of_choice = ""
    if options.framework == "docker":
        if docker_installed == 1:
            framework_of_choice = "docker"
        else:
            framework_of_choice = "singularity"

    if options.framework == "singularity":
        if singularity_installed == 1:
            framework_of_choice = "singularity"
        else:
            framework_of_choice = "docker"

    ################################################################################################################################################################################################################################################
    # Pull down docker or singularity images
    ################################################################################################################################################################################################################################################

    list_of_softwares_with_versions = {"samtools":"1.14",
                                       "zpaq":"715",
                                       "fclqc":"latest",
                                       "abridge":"1.1.0"}

    if framework_of_choice == "docker":
        for software in list_of_softwares_with_versions:
            version = list_of_softwares_with_versions[software]
            os.system( f"docker pull ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/{software}:{version}" )
    else:
        for software in list_of_softwares_with_versions:
            version = list_of_softwares_with_versions[software]
            os.system( f"singularity pull {options.output_directory}/singularity_images/{software}:{version} docker://ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/{software}:{version}" )
    ################################################################################################################################################################################################################################################

    cmd = f"samtools faidx {options.output_directory}/{genome_filename_without_location}"

    if os.path.exists( f"{options.output_directory}/{genome_filename_without_location}.fai" ) == False:
        if options.framework == "docker":
            runDockerCommand( logging,
                              name = "samtools",
                                version = list_of_softwares_with_versions['samtools'],
                                image_location = f"ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'
                )

        elif options.framework == "singularity":
            runSingularityCommand( logging,
                                name = "samtools",
                                version = list_of_softwares_with_versions['samtools'],
                                image_location = "ghcr.io/sagnikbanerjee15/docker_tools_and_pipelines/samtools",
                                container_name = f"{options.output_directory.split('/')[-1]}",
                                volumes = volumes_list,
                                command = cmd,
                                cpus = options.cpu,
                                memory = '100g'

                )

    if options.compress == True:
        prepareInputFilesForCompressing( options, list_of_softwares_with_versions, remove_these_files, volumes_list, logging )
        logging.info( f"Input files have been prepared" )

    if options.inputfilename is not None:
        input_filename_without_location = options.inputfilename.split( "/" )[-1][:-4]
    else:
        input_filename_without_location = options.inputabrfilename.split( "/" )[-1][:-8]

    if options.output_directory is None:
        options.output_directory = "/".join( options.inputfilename.split( "/" )[:-1] )

    for line in pprint.pformat( options ).split( '\n' ):
        logging.info( line )

    if options.compress == True:
        alterReadNamesAndAddNHTag( options, logging, list_of_softwares_with_versions, volumes_list, remove_these_files )
        if options.quiet == False:
            logging.info( f"Read names have been altered and NH tags have been added" )

    if options.compress == True:
        findEndedness( options, logging )
        if options.quiet == False:
            logging.info( f"findEndedness() execution is complete" )

    if options.compress == True:
        compressSamFile( options, list_of_softwares_with_versions, volumes_list )
        if options.quiet == False:
            logging.info( f"compressSamFile() execution is complete" )

    ###################################################################################################################  EXAMINED TILL HERE
    return

    if options.decompress == True:
        decompressSamFile( options )
        if options.quiet == False:
            logging.info( f"decompressSamFile() execution is complete" )

    if options.header == True:
        """
        cmd=f"7za e {options.inputfilename[0]} -y"
        if options.quiet == False:
            logging.info(f"Running command - {cmd}")
        os.system(cmd)
        """
        cmd = f"cat {options.inputfilename[0][:-3]}|grep ^@ > {options.inputfilename[0][:-3]}.headers"
        os.system( cmd )
        # print(open(f"{options.inputfilename[0][:-3]}.headers","r").read())
        os.system( f"rm -f {options.inputfilename[0][:-3]}.headers" )
    """
    if options.random == True:
        input_filename = options.inputabrfilename
        name_of_input_file_without_location = input_filename.split( "/" )[-1][:-8]
        _outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise"
        _index_outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise_index"
        unmapped_outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise_unmapped"
        name_of_file_with_quality_scores = f"{options.output_directory}/{name_of_input_file_without_location}.sam_concise_qual"
        compressed_abridged_filename = input_filename
        output_sam_filename = options.output_directory + "/" + name_of_input_file_without_location + ".decompressed.sam"

        cmd = f"7za e {input_filename} -y "
        cmd += f" -o{options.output_directory}"
        cmd += f" 1> /dev/null 2>/dev/null"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )

        if options.inputabrfilename[-3:] == ".br":
            cmd = f"brotli -d -k -f {_outputfilename}.br {_index_outputfilename}.br {unmapped_outputfilename}.br {name_of_file_with_quality_scores}.rle.br"
            os.system( cmd )

        cmd = f"cat {_outputfilename}|grep ^@ > {options.output_directory}/{name_of_input_file_without_location}.headers"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )
        chromosome_to_length = {}
        fhr = open( f"{options.output_directory}/{name_of_input_file_without_location}.headers", "r" )
        for line in fhr:
            useless, chromosome, length = line.strip().split( "\t" )
            chromosome = chromosome.split( ":" )[-1]
            length = length.split( ":" )[-1]
            # print(useless,chromosome,length)
            chromosome_to_length[chromosome] = int( length )
        fhr.close()
        if options.positions.count( ":" ) != 1 or options.positions.count( "-" ) != 1:
            print( "Error in position. Please specify in chromosome:start-end format" )
            sys.exit()
        chromosome = options.positions.split( ":" )[0]
        start, end = options.positions.split( ":" )[-1].split( "-" )
        start, end = int( start ), int( end )
        if start > chromosome_to_length[chromosome] or end > chromosome_to_length[chromosome] or start > end:
            print( "Error in chromosome lengths" )
            sys.exit()
        retrieveAlignmentsRandomly( chromosome, start, end, options )
        os.system( f"rm -rf {options.output_directory}" )
    """
    if options.generate_overlapping_coverage == True or options.generate_non_overlapping_coverage == True:
        input_filename = options.inputabrfilename
        name_of_input_file_without_location = input_filename.split( "/" )[-1][:-8]
        _outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise"
        _index_outputfilename = options.output_directory + "/" + name_of_input_file_without_location + ".sam_concise_index"

        cmd = f"7za e {input_filename} -y "
        cmd += f" -o{options.output_directory}"
        cmd += f" 1> /dev/null 2>/dev/null"
        if options.quiet == False:
            logging.info( f"Running command - {cmd}" )
        os.system( cmd )

        if options.inputabrfilename[-3:] == ".br":
            cmd = f"brotli -d -k -f {_outputfilename}.br {_index_outputfilename}.br"
            os.system( cmd )

        generateCoverage( _outputfilename, _index_outputfilename, options )
        os.system( f"rm -rf {options.output_directory}" )

    cleanUp( options )
    if options.quiet == False:
        logging.info( f"cleanUp() execution is complete" )


if __name__ == "__main__":
    main()
